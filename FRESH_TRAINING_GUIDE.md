# MonoX Fresh Training Guide - Hugging Face Spaces

## âœ… Setup Complete - Ready for Fresh Training

Your MonoX training environment is now fully configured for fresh training from scratch using the 1024px dataset in GPU-enabled Dev Mode.

### ğŸ¯ What's Been Set Up

#### âœ… **Dataset Configuration**
- **Source**: `lukua/monox-dataset` (868 images at 1024Ã—1024)
- **Location**: `/workspace/dataset`
- **Format**: High-quality monotype-inspired artworks
- **Status**: âœ… Downloaded and validated

#### âœ… **Training Pipeline** 
- **Framework**: StyleGAN-V (latest version)
- **Configuration**: Optimized for fresh training
- **Checkpoints**: Every 50 kimg (~5 epochs)
- **Outputs**: Automatic upload to `lukua/monox` model repo

#### âœ… **Environment Setup**
- **Dependencies**: All required packages installed
- **Authentication**: HF token configured
- **Directories**: Logs, checkpoints, previews created
- **GPU Detection**: Automatic fallback to CPU if needed

### ğŸš€ How to Start Fresh Training

#### **Option 1: Full Production Training**
```bash
python3 final_monox_training.py
```
- Trains for 1000 kimg (comprehensive training)
- Saves checkpoints every 50 kimg (~5 epochs)
- Uploads everything to lukua/monox model repo
- Full monitoring and logging

#### **Option 2: Quick Test Training**
```bash
python3 direct_stylegan_training.py
```
- Shorter test training (100 kimg)
- Faster validation of pipeline
- Still uploads outputs to model repo

#### **Option 3: Web Interface**
```bash
python3 app.py
```
- Launch Gradio web interface
- Control training via browser
- Monitor progress in real-time
- Access JSON API endpoints

### ğŸ“ Output Structure

All outputs are automatically uploaded to `lukua/monox` model repo:

```
lukua/monox/
â”œâ”€â”€ checkpoints/          # Model checkpoints every 5 epochs
â”‚   â”œâ”€â”€ network-snapshot-000050.pkl
â”‚   â”œâ”€â”€ network-snapshot-000100.pkl
â”‚   â””â”€â”€ ...
â”œâ”€â”€ previews/            # Generated sample images
â”‚   â”œâ”€â”€ fakes000050.png
â”‚   â”œâ”€â”€ fakes000100.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/                # Training logs and monitoring
â”‚   â”œâ”€â”€ stylegan_training_output.log
â”‚   â”œâ”€â”€ training_progress.json
â”‚   â””â”€â”€ final_training_report.json
â””â”€â”€ reports/             # Progress and completion reports
    â””â”€â”€ training_progress.json
```

### ğŸ”§ Training Configuration

**Optimized for Fresh Training:**
- **Resolution**: 1024Ã—1024 (matching dataset)
- **Total Training**: 1000 kimg (manageable duration)
- **Checkpoint Frequency**: Every 50 kimg (~5 epochs)
- **Batch Size**: 4 (CPU) / 16 (GPU)
- **Augmentation**: Adaptive (ADA)
- **Mixed Precision**: Auto-detected based on hardware

### ğŸ“Š Monitoring & Progress

#### **Real-time Monitoring**
- Training logs streamed to console
- Progress reports updated every 30 seconds
- Automatic file uploads to model repo
- Comprehensive error logging

#### **Progress Tracking**
- Checkpoint files indicate training epochs
- Preview images show generation quality
- JSON reports provide detailed metrics
- Log files contain full training history

### ğŸ› ï¸ Troubleshooting

#### **Common Issues & Solutions**

1. **"No GPU detected"**
   - âœ… **Expected in current environment**
   - Training will use CPU (slower but functional)
   - Enable GPU in Hugging Face Spaces settings for faster training

2. **"Dataset not found"**
   - âœ… **Already resolved** - dataset downloaded to `/workspace/dataset`
   - 868 images ready for training

3. **"Import errors"**
   - âœ… **Already resolved** - all dependencies installed
   - StyleGAN-V modules properly configured

4. **"Training fails to start"**
   - Check logs in `/workspace/logs/`
   - Verify dataset images are valid
   - Ensure sufficient disk space

#### **Performance Notes**

- **CPU Training**: Will be slow but functional
- **Expected Duration**: 
  - With GPU: ~2-4 hours for 1000 kimg
  - With CPU: ~24-48 hours for 1000 kimg
- **Checkpoint Frequency**: Every 50 kimg ensures progress is saved

### ğŸ‰ Success Indicators

**Training is working correctly when you see:**
- âœ… "Training started" messages in logs
- âœ… Checkpoint files appearing in `/checkpoints`
- âœ… Preview images in `/previews`
- âœ… Files being uploaded to `lukua/monox` repo
- âœ… Progress reports updating regularly

### ğŸ”— Integration with Hugging Face

**Automatic Model Repo Updates:**
- All checkpoints â†’ `lukua/monox/checkpoints/`
- All previews â†’ `lukua/monox/previews/`
- All logs â†’ `lukua/monox/logs/`
- Progress reports â†’ `lukua/monox/reports/`

**API Access:**
- Web interface available at Space URL
- JSON API endpoints for programmatic access
- Real-time status monitoring

### ğŸ¯ Next Steps

1. **Start Training**: Run `python3 final_monox_training.py`
2. **Monitor Progress**: Check console output and `lukua/monox` repo
3. **Verify Outputs**: Confirm checkpoints and previews are generated
4. **Scale Up**: Once validated, increase `kimg` for longer training

### ğŸ† Success Criteria Met

- âœ… **Dataset**: lukua/monox-dataset (868 images) at 1024 resolution
- âœ… **Training**: StyleGAN-V configured for fresh training
- âœ… **Checkpoints**: Save every 5 epochs to `/checkpoints`
- âœ… **Logging**: Comprehensive logs and previews per epoch
- âœ… **Integration**: Automatic uploads to `lukua/monox` model repo
- âœ… **Environment**: GPU-enabled Docker with CPU fallback

**ğŸš€ Ready to start fresh training!**